{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d1a7e0-4998-46e2-b3aa-77be1608fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-Oct-24 18:50:09: C:\\Users\\getma\\AppData\\Local\\Temp\\ipykernel_20388\\629242470.py:89: RuntimeWarning: invalid value encountered in arccos\n",
      "  imfconeanglevalues=np.arccos(bxvalues/bmagvalues)*180/np.pi # converted to degrees written in python as \\N{DEGREE SIGN}\n",
      "\n",
      "22-Oct-24 18:50:09: C:\\Users\\getma\\AppData\\Local\\Temp\\ipykernel_20388\\629242470.py:105: RuntimeWarning: divide by zero encountered in divide\n",
      "  epsilonvalues=1e-3*1e-9*poyntingvalues*4*np.pi*(7*6.3781*1e6)**2*np.sin(np.arctan(bygsmvalues/bzgsmvalues)/2)**4 # values are in GW\n",
      "\n",
      "22-Oct-24 18:50:09: C:\\Users\\getma\\AppData\\Local\\Temp\\ipykernel_20388\\629242470.py:105: RuntimeWarning: invalid value encountered in divide\n",
      "  epsilonvalues=1e-3*1e-9*poyntingvalues*4*np.pi*(7*6.3781*1e6)**2*np.sin(np.arctan(bygsmvalues/bzgsmvalues)/2)**4 # values are in GW\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If your PC can handle multiprocessing, use the other dataprocessingmultiprocess file\n",
    "\n",
    "# Be sure to first have pyspedas installed first through: pip install pyspedas or update with pip install --upgrade & pip install pyspedas --upgrade\n",
    "# Other packages may include: pip install pandas --upgrade & pip install statsmodels --upgrade\n",
    "import csv\n",
    "import pandas\n",
    "import pyspedas\n",
    "from pyspedas import time_double\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from scipy import stats\n",
    "#from scipy.stats import mannwhitneyu\n",
    "#from scipy.stats import ranksums\n",
    "#from scipy.signal import medfilt\n",
    "\n",
    "# Download the .csv file from SuperMAG at https://supermag.jhuapl.edu/substorms/ (an account is required, just make it anonymous), rename it to \"substormdata.csv\"\n",
    "# Use the following for Linux/Mac:\n",
    "#datadirectory=os.path.expanduser('~')+'/Downloads/Data/' # The ending forward slash is necessary\n",
    "# Use the following for Windows:\n",
    "datadirectory=os.path.join(os.path.join(os.environ['USERPROFILE']),'Downloads\\\\Data\\\\') # The two ending back slashes are necessary\n",
    "\n",
    "# It may be necessary to use a conversion factor on some of these parameters, example:\n",
    "tempconversionfactor=8.61732814974493*1e-5 # for K to eV in temperature\n",
    "\n",
    "substormfile=datadirectory+'substormdata.csv'\n",
    "with open(substormfile,'r') as csv_file:\n",
    "    csv_reader=csv.reader(csv_file)\n",
    "substormdata=pandas.read_csv(substormfile)\n",
    "substormtime=substormdata.iloc[0:len(substormdata),0]\n",
    "subtrange=time_double(substormtime)\n",
    "\n",
    "# Requires the use of omnisave.ipynb first\n",
    "# For more info on these parameters, visit https://cdaweb.gsfc.nasa.gov/misc/NotesO.html#OMNI_HRO2_1MIN\n",
    "loadedarrays=np.load(datadirectory+'myomnidata.npz')\n",
    "bxtimes=loadedarrays['arr_0']\n",
    "imfvalues=loadedarrays['arr_1']\n",
    "plsvalues=loadedarrays['arr_2']\n",
    "imfptsvalues=loadedarrays['arr_3']\n",
    "plsptsvalues=loadedarrays['arr_4']\n",
    "percinterpvalues=loadedarrays['arr_5']\n",
    "timeshiftvalues=loadedarrays['arr_6']\n",
    "rmstimeshiftvalues=loadedarrays['arr_7']\n",
    "rmsphasevalues=loadedarrays['arr_8']\n",
    "timebtwnobsvalues=loadedarrays['arr_9']\n",
    "bmagvalues=loadedarrays['arr_10']\n",
    "bxvalues=loadedarrays['arr_11']\n",
    "byvalues=loadedarrays['arr_12']\n",
    "bzvalues=loadedarrays['arr_13']\n",
    "bygsmvalues=loadedarrays['arr_14']\n",
    "bzgsmvalues=loadedarrays['arr_15']\n",
    "rmssdbvalues=loadedarrays['arr_16']\n",
    "rmssdfldvecvalues=loadedarrays['arr_17']\n",
    "speedvalues=loadedarrays['arr_18']\n",
    "vxvalues=loadedarrays['arr_19']\n",
    "vyvalues=loadedarrays['arr_20']\n",
    "vzvalues=loadedarrays['arr_21']\n",
    "protondenvalues=loadedarrays['arr_22']\n",
    "temperaturevalues=loadedarrays['arr_23']*tempconversionfactor\n",
    "alpharatiovalues=loadedarrays['arr_24']\n",
    "flowpressurevalues=loadedarrays['arr_25']\n",
    "efieldmeasuredvalues=loadedarrays['arr_26']\n",
    "betavalues=loadedarrays['arr_27']\n",
    "alfmachvalues=loadedarrays['arr_28']\n",
    "magmachvalues=loadedarrays['arr_29']\n",
    "xposvalues=loadedarrays['arr_30']\n",
    "yposvalues=loadedarrays['arr_31']\n",
    "zposvalues=loadedarrays['arr_32']\n",
    "bowshockxvalues=loadedarrays['arr_33']\n",
    "bowshockyvalues=loadedarrays['arr_34']\n",
    "bowshockzvalues=loadedarrays['arr_35']\n",
    "aeindexvalues=loadedarrays['arr_36']\n",
    "alindexvalues=loadedarrays['arr_37']\n",
    "auindexvalues=loadedarrays['arr_38']\n",
    "symdvalues=loadedarrays['arr_39']\n",
    "symhvalues=loadedarrays['arr_40']\n",
    "asydvalues=loadedarrays['arr_41']\n",
    "asyhvalues=loadedarrays['arr_42']\n",
    "\n",
    "# Add any derived parameters, take note of units\n",
    "efieldxgsecalculatedvalues=1e3*1e3*1e-9*(vzvalues*byvalues-vyvalues*bzvalues) # values are in mV/m\n",
    "efieldygsecalculatedvalues=1e3*1e3*1e-9*(vxvalues*bzvalues-vzvalues*bxvalues) # values are in mV/m\n",
    "efieldzgsecalculatedvalues=1e3*1e3*1e-9*(vyvalues*bxvalues-vxvalues*byvalues) # values are in mV/m\n",
    "efieldcalculatedvalues=np.sqrt(efieldxgsecalculatedvalues**2+efieldygsecalculatedvalues**2+efieldzgsecalculatedvalues**2) # values are in mV/m\n",
    "magpressurevalues=1e9*(bmagvalues*1e-9)**2/(2*1.256637062*1e-6) # values are in nPa\n",
    "alfvenspeedvalues=1e-3*1e-9*bmagvalues/np.sqrt(1.256637062*1e-6*1e6*protondenvalues*1.672621923*1e-27*(1+alpharatiovalues)) # values are in km/s\n",
    "entropyvalues=temperaturevalues*(protondenvalues)**(-2/3) # values are in eV*cm^2\n",
    "imfconeanglevalues=np.arccos(bxvalues/bmagvalues)*180/np.pi # converted to degrees written in python as \\N{DEGREE SIGN}\n",
    "# The following below is an attempt to make the clock angle useable, unfortunately it still jumps from 0 to 360, and I don't know what to do about that\n",
    "#for i in range(len(bygsmvalues)):\n",
    "#    if bygsmvalues[i]>=0 and bzgsmvalues[i]>=0:\n",
    "#        imfclockanglevalues[i]=np.arctan(np.abs(bygsmvalues[i]/bzgsmvalues[i]))*180/np.pi # converted to degrees written in python as \\N{DEGREE SIGN}\n",
    "#    if bygsmvalues[i]>=0 and bzgsmvalues[i]<0:\n",
    "#        imfclockanglevalues[i]=np.arctan(np.abs(bzgsmvalues[i]/bygsmvalues[i]))*180/np.pi+90\n",
    "#    if bygsmvalues[i]<0 and bzgsmvalues[i]<0:\n",
    "#        imfclockanglevalues[i]=np.arctan(np.abs(bygsmvalues[i]/bzgsmvalues[i]))*180/np.pi+180\n",
    "#    if bygsmvalues[i]<0 and bzgsmvalues[i]>=0:\n",
    "#        imfclockanglevalues[i]=np.arctan(np.abs(bzgsmvalues[i]/bygsmvalues[i]))*180/np.pi+270\n",
    "#    if bygsmvalues[i]==np.nan:\n",
    "#        imfclockanglevalues[i]=np.nan\n",
    "#    if bzgsmvalues[i]==np.nan:\n",
    "#        imfclockanglevalues[i]=np.nan\n",
    "poyntingvalues=1e3*(1/(1.256637062*1e-6))*1e3*1e-18*speedvalues*bmagvalues**2 # values are in mW/m^2\n",
    "epsilonvalues=1e-3*1e-9*poyntingvalues*4*np.pi*(7*6.3781*1e6)**2*np.sin(np.arctan(bygsmvalues/bzgsmvalues)/2)**4 # values are in GW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be67e8a-3927-4fb1-b3de-08545e6ab999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16-May-24 09:03:35: /tmp/ipykernel_486778/3631649961.py:36: RuntimeWarning: Mean of empty slice\n",
      "  paramaverage=np.nanmean(paramimportant.reshape(-1,(interval)),axis=1) # Takes the average of each interval # of terms\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time To Calculate: 8.133403062820435 seconds (0.1355568011601766 minutes) ---\n"
     ]
    }
   ],
   "source": [
    "# This is comparing background IMF values to times around substorms, no cutoff value for the time between substorms\n",
    "\n",
    "# Select parameter & time interval to look at:\n",
    "paramvalues=bzvalues\n",
    "filename='bzvalues'\n",
    "start=-15 # Negative means before substorm, values in minutes\n",
    "end=15\n",
    "interval=10   # Increasing this interval will smooth out the data but possibly leave out details\n",
    "\n",
    "starttime=time.time()\n",
    "varrange=range(start,end+1)\n",
    "\n",
    "substarttime=[]\n",
    "for i in range(len(subtrange)):\n",
    "    substarttime.append(subtrange[i]-60*(interval/2))\n",
    "subindex=bxtimes.searchsorted(substarttime) # Finds the index of each starting time. This is such a neat trick that should be documented more on, greatly reduces calculation time\n",
    "\n",
    "paramvalues=paramvalues.astype('float') # Only works with float values apparently\n",
    "paramvalues[paramvalues==0]=np.nan # Some variables that have many points measured at exactly 0 should actually be nan values\n",
    "paramvalues[paramvalues==np.inf]=np.nan # Same as above but for inf values, usually occur when dividing by 0\n",
    "paramvalues[paramvalues==999999]=np.nan # Other files may use this as the default for no value like SME Data.csv\n",
    "multiresults=[]\n",
    "ttest=[]\n",
    "tpvalues=[]\n",
    "means=[]\n",
    "variances=[]\n",
    "for i in varrange:\n",
    "    delayedsubindex=subindex+i\n",
    "    paramimportant=[]\n",
    "    for i in delayedsubindex:\n",
    "        for j in range(interval):\n",
    "            paramimportant.append(paramvalues[i+j])\n",
    "    paramimportant=np.array(paramimportant)\n",
    "    paramaverage=[]\n",
    "    paramaverage=np.array(paramaverage)\n",
    "    paramaverage=np.nanmean(paramimportant.reshape(-1,(interval)),axis=1) # Takes the average of each interval # of terms\n",
    "    ttestvalues=stats.ttest_ind(a=paramvalues[~np.isnan(paramvalues)],b=paramaverage[~np.isnan(paramaverage)],equal_var=False) # The variations are NOT equal, so this is a Welch Test\n",
    "    ttest.append(np.abs(ttestvalues.statistic))\n",
    "    tpvalues.append(ttestvalues.pvalue)\n",
    "    means.append(np.nanmean(paramaverage))\n",
    "    variances.append(np.nanvar(paramaverage))\n",
    "\n",
    "genmean=np.array(np.nanmean(paramvalues)) # These must also be converted in order to be saved as an array by np.savez\n",
    "genvariance=np.array(np.nanvar(paramvalues))\n",
    "print(\"--- Time To Calculate: \"+str(time.time()-starttime)+\" seconds (\"+str((time.time()-starttime)/60)+\" minutes) ---\")\n",
    "\n",
    "np.savez(datadirectory+str(filename)+'start'+str(start)+'end'+str(end)+'interval'+str(interval)+'processeddata.npz',ttest,tpvalues,means,variances,genmean,genvariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a88003-140d-4d08-b851-a6b49b02db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-Oct-24 18:57:19: C:\\Users\\getma\\AppData\\Local\\Temp\\ipykernel_20388\\889456197.py:37: RuntimeWarning: Mean of empty slice\n",
      "  paramvaluesgen=np.nanmean(paramvaluesgen.reshape(-1,(abs(averageend-averagestart)+1)),axis=1) # Takes the average of each time period before a substorm onset\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time To Calculate: 0.7189993858337402 seconds (0.011983323097229003 minutes) ---\n",
      "Percent of substorms that fit the range criteria: 20.44747772003423 %\n",
      "--- Time To Save File: 0.08600115776062012 seconds (0.0014333526293436687 minutes) ---\n"
     ]
    }
   ],
   "source": [
    "# This is including the cutoff time for the minimum time interval between substorms, and this is comparing onset with its immediate surrounding times\n",
    "\n",
    "# Select parameter & time interval to look at:\n",
    "paramvalues=efieldcalculatedvalues\n",
    "filename='efieldcalculatedvalues'\n",
    "\n",
    "start=-120 # Negative means before substorm, values in minutes\n",
    "end=120\n",
    "substormcutoff=6*60 # For the minimum time in-between substorms i.e. there must be a period of at least x minutes before an onset event that contains no other onsets\n",
    "averagestart=-5 # To calculte the total background averages, a range must be given i.e. a range between 60 and 30 minutes before an onset would be -60 and -30\n",
    "averageend=5\n",
    "\n",
    "# !!!WARNING!!!  This process is sped up via multiprocessing on all CPU cores, may slow down PC as a result  !!!WARNING!!!\n",
    "\n",
    "starttime=time.time()\n",
    "varrange=range(start,end+1)\n",
    "\n",
    "subindex=bxtimes.searchsorted(subtrange) # Finds the index of each starting time. This is such a neat trick that should be documented more on, greatly reduces calculation time\n",
    "subindex=list(subindex)\n",
    "for i in reversed(range(len(subindex)-1)):\n",
    "    if subindex[i]-subindex[i-1]<substormcutoff: # Value again in minutes\n",
    "        del subindex[i]\n",
    "subindex=np.concatenate((574,subindex),axis=None) # The first value needs to be replaced here\n",
    "\n",
    "#paramvalues[paramvalues==0]=np.nan # Some variables that have many points measured at exactly 0 should actually be nan values\n",
    "#paramvalues[paramvalues==np.inf]=np.nan # Same as above but for inf values, usually occur when dividing by 0\n",
    "#paramvalues[paramvalues==999999]=np.nan # Other files may use this as the default for no value\n",
    "\n",
    "paramvaluesgen=[]\n",
    "for i in subindex:\n",
    "    for j in range(averagestart,averageend+1):\n",
    "        paramvaluesgen.append(paramvalues[i+j])\n",
    "genmean=np.array(np.nanmean(paramvaluesgen)) # These must also be converted in order to be saved as an array by np.savez\n",
    "genvariance=np.array(np.nanvar(paramvaluesgen))\n",
    "\n",
    "paramvaluesgen=np.array(paramvaluesgen)\n",
    "paramvaluesgen=np.nanmean(paramvaluesgen.reshape(-1,(abs(averageend-averagestart)+1)),axis=1) # Takes the average of each time period before a substorm onset\n",
    "paramvaluesgen=paramvaluesgen.astype('float') # Only works with float values apparently\n",
    "\n",
    "\n",
    "\n",
    "ttest=[]\n",
    "tpvalues=[]\n",
    "means=[]\n",
    "variances=[]\n",
    "importantvalues=[]\n",
    "for i in varrange:\n",
    "    delayedsubindex=subindex+i\n",
    "    paramimportant=[]\n",
    "    for i in delayedsubindex:\n",
    "        paramimportant.append(paramvalues[i])\n",
    "    importantvalues.append(paramimportant)\n",
    "    paramimportant=np.array(paramimportant) # The test requires this apparently\n",
    "    ttestvalues=stats.ttest_ind(a=paramvaluesgen[~np.isnan(paramvaluesgen)],b=paramimportant[~np.isnan(paramimportant)],equal_var=False) # The variations are NOT equal, so this is a Welch Test\n",
    "    ttest.append(np.abs(ttestvalues.statistic))\n",
    "    tpvalues.append(ttestvalues.pvalue)\n",
    "    means.append(np.nanmean(paramimportant))\n",
    "    variances.append(np.nanvar(paramimportant))\n",
    "\n",
    "print(\"--- Time To Calculate: \"+str(time.time()-starttime)+\" seconds (\"+str((time.time()-starttime)/60)+\" minutes) ---\")\n",
    "print('Percent of substorms that fit the range criteria: '+str(len(subindex)/len(subtrange)*100)+' %')\n",
    "\n",
    "starttime=time.time()\n",
    "#np.savez(datadirectory+str(filename)+'start'+str(start)+'end'+str(end)+'nointerval'+'processeddata.npz',ttest,tpvalues,means,variances,genmean,genvariance,kstest,kspvalues,cvtest,cvpvalues,rstest,rspvalues,mwtest,mwpvalues)\n",
    "# Comment out below if including the above terms\n",
    "np.savez(datadirectory+str(filename)+'start'+str(start)+'end'+str(end)+'nointerval'+str(substormcutoff)+str(averagestart)+str(averageend)+'processeddata.npz',ttest,tpvalues,means,variances,genmean,genvariance,importantvalues)\n",
    "#np.savez(datadirectory+str(filename)+'start'+str(start)+'end'+str(end)+'nointerval'+str(substormcutoff)+str(averagestart)+str(averageend)+'processeddata.npz',ttest,tpvalues,means,variances,genmean,genvariance)\n",
    "print(\"--- Time To Save File: \"+str(time.time()-starttime)+\" seconds (\"+str((time.time()-starttime)/60)+\" minutes) ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f84f27-12b6-4ef0-b4e1-0207af26deb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
